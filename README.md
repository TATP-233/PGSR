# PGSR: Planar-based Gaussian Splatting for Efficient and High-Fidelity Surface Reconstruction
Danpeng Chen, Hai Li, [Weicai Ye](https://ywcmaike.github.io/), Yifan Wang, Weijian Xie, Shangjin Zhai, Nan Wang, Haomin Liu, Hujun Bao, [Guofeng Zhang](http://www.cad.zju.edu.cn/home/gfzhang/)
### [Project Page](https://zju3dv.github.io/pgsr/) | [arXiv](https://arxiv.org/abs/2406.06521)
![Teaser image](assets/teaser.jpg)

We present a Planar-based Gaussian Splatting Reconstruction representation for efficient and high-fidelity surface reconstruction from multi-view RGB images without any geometric prior (depth or normal from pre-trained model).  

## Updates
- [2024.07.18]: We fine-tuned the hyperparameters based on the original paper. The Chamfer Distance on the DTU dataset decreased to 0.47.

The Chamfer Distanceâ†“ on the DTU dataset
|     | 24| 37| 40| 55| 63| 65| 69| 83| 97|105|106|110|114|118|122|Mean|Time|
|-------|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|
|PGSR(Paper)|0.34|0.58|0.29|0.29|0.78|0.58|0.54|1.01|0.73|0.51|0.49|0.69|0.31|0.37|0.38|0.53|0.6h|
|PGSR(Code_V1.0)|0.33|0.51|0.29|0.28|0.75|0.53|0.46|0.92|0.62|0.48|0.45|0.55|0.29|0.33|0.31|0.47|0.5h|
|PGSR(Remove ICP)|0.36|0.57|0.38|0.33|0.78|0.58|0.50|1.08|0.63|0.59|0.46|0.54|0.30|0.38|0.34|0.52|0.5h|

The F1 Scoreâ†‘ on the TnT dataset
||PGSR(Paper)|PGSR(Code_V1.0)
|-|-|-|
|Barn|0.66|0.65
|Caterpillar|0.41|0.44
|Courthouse|0.21|0.20
|Ignatius|0.80|0.81
|Meetingroom|0.29|0.32
|Truck|0.60|0.66
|Mean|0.50|0.51
|Time|1.2h|45m

## Installation

The repository contains submodules, thus please check it out with 
```shell
# SSH
git clone git@github.com:zju3dv/PGSR.git
cd PGSR

conda create -n pgsr python=3.8
conda activate pgsr

pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 #replace your cuda version
pip install -r requirements.txt
pip install submodules/diff-plane-rasterization
pip install submodules/simple-knn
```

## Dataset Preprocess
Please download the preprocessed DTU dataset from [2DGS](https://surfsplatting.github.io/), the Tanks and Temples dataset from [official webiste](https://www.tanksandtemples.org/download/), the Mip-NeRF 360 dataset from the [official webiste](https://jonbarron.info/mipnerf360/). You need to download the ground truth point clouds from the [DTU dataset](https://roboimagedata.compute.dtu.dk/?page_id=36). For the Tanks and Temples dataset, you need to download the reconstruction, alignment and cropfiles from the [official webiste](https://jonbarron.info/mipnerf360/). 

The data folder should like this:
```shell
data
â”œâ”€â”€ dtu_dataset
â”‚Â Â  â”œâ”€â”€ dtu
â”‚   â”‚   â”œâ”€â”€ scan24
â”‚   â”‚   â”‚   â”œâ”€â”€ images
â”‚   â”‚   â”‚   â”œâ”€â”€ mask
â”‚   â”‚   â”‚   â”œâ”€â”€ sparse
â”‚   â”‚   â”‚   â”œâ”€â”€ cameras_sphere.npz
â”‚   â”‚   â”‚   â””â”€â”€ cameras.npz
â”‚   â”‚   â””â”€â”€ ...
â”‚Â Â  â”œâ”€â”€ dtu_eval
â”‚   â”‚   â”œâ”€â”€ Points
â”‚   â”‚   â”‚   â””â”€â”€ stl
â”‚   â”‚   â””â”€â”€ ObsMask
â”œâ”€â”€ tnt_dataset
â”‚Â Â  â”œâ”€â”€ tnt
â”‚   â”‚   â”œâ”€â”€ Ignatius
â”‚   â”‚   â”‚   â”œâ”€â”€ images_raw
â”‚   â”‚   â”‚   â”œâ”€â”€ Ignatius_COLMAP_SfM.log
â”‚   â”‚   â”‚   â”œâ”€â”€ Ignatius_trans.txt
â”‚   â”‚   â”‚   â”œâ”€â”€ Ignatius.json
â”‚   â”‚   â”‚   â”œâ”€â”€ Ignatius_mapping_reference.txt
â”‚   â”‚   â”‚   â””â”€â”€ Ignatius.ply
â”‚   â”‚   â””â”€â”€ ...
â””â”€â”€ MipNeRF360
    â”œâ”€â”€ bicycle
    â””â”€â”€ ...
```

Then run the scripts to preprocess Tanks and Temples dataset:
```shell
# Install COLMAP
Refer to https://colmap.github.io/install.html

# Tanks and Temples dataset
python scripts/preprocess/convert_tnt.py --tnt_path your_tnt_path
```

## Training and Evaluation
```shell
# Fill in the relevant parameters in the script, then run it.

# DTU dataset
python scripts/run_dtu.py

# Tanks and Temples dataset
python scripts/run_tnt.py

# Mip360 dataset
python scripts/run_mip360.py
```

## Custom Dataset
The data folder should like this:
```shell
data
â”œâ”€â”€ data_name1
â”‚Â Â  â””â”€â”€ input
â”‚       â”œâ”€â”€ *.jpg/*.png
â”‚       â””â”€â”€ ...
â”œâ”€â”€ data_name2
â””â”€â”€ ...
```
Then run the following script to preprocess the dataset and to train and test:
```shell
# Preprocess dataset
python scripts/preprocess/convert.py --data_path your_data_path
```

#### Some Suggestions:
- Adjust the threshold for selecting the nearest frame in ModelParams based on the dataset;
- -r n: Downsample the images by a factor of n to accelerate the training speed;
- --max_abs_split_points 0: For weakly textured scenes, to prevent overfitting in areas with weak textures, we recommend disabling this splitting strategy by setting it to 0;
- --opacity_cull_threshold 0.05: To reduce the number of Gaussian point clouds in a simple way, you can set this threshold.
```shell
# Training
python train.py -s data_path -m out_path --max_abs_split_points 0 --opacity_cull_threshold 0.05
```

#### Some Suggestions:
- Adjust max_depth and voxel_size based on the dataset;
- --use_depth_filter: Enable depth filtering to remove potentially inaccurate depth points using single-view and multi-view techniques. For scenes with floating points or insufficient viewpoints, it is recommended to turn this on.
```shell
# Rendering and Extract Mesh
python render.py -m out_path --max_depth 10.0 --voxel_size 0.01
```

## Acknowledgements
This project is built upon [3DGS](https://github.com/graphdeco-inria/gaussian-splatting). Densify is based on [AbsGau](https://ty424.github.io/AbsGS.github.io/) and [GOF](https://github.com/autonomousvision/gaussian-opacity-fields?tab=readme-ov-file). DTU and Tanks and Temples dataset preprocess are based on [Neuralangelo scripts](https://github.com/NVlabs/neuralangelo/blob/main/DATA_PROCESSING.md). Evaluation scripts for DTU and Tanks and Temples dataset are based on [DTUeval-python](https://github.com/jzhangbs/DTUeval-python) and [TanksAndTemples](https://github.com/isl-org/TanksAndTemples/tree/master/python_toolbox/evaluation) respectively. We thank all the authors for their great work and repos. 


## Citation

If you find this code useful for your research, please use the following BibTeX entry.

```bibtex
@article{chen2024pgsr,
  title={PGSR: Planar-based Gaussian Splatting for Efficient and High-Fidelity Surface Reconstruction},
  author={Chen, Danpeng and Li, Hai and Ye, Weicai and Wang, Yifan and Xie, Weijian and Zhai, Shangjin and Wang, Nan and Liu, Haomin and Bao, Hujun and Zhang, Guofeng},
  journal={arXiv preprint arXiv:2406.06521},
  year={2024}
}
```

# LiDAR-PGSR

åŸºäºPGSRå’ŒLiDAR-RTçš„é«˜ç²¾åº¦LiDARæ¨¡æ‹Ÿé¡¹ç›®

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®æ—¨åœ¨ç»“åˆPGSR (Planar Gaussian Splatting Reconstruction) å’Œ LiDAR-RT çš„ä¼˜åŠ¿ï¼Œå®ç°é«˜ç²¾åº¦çš„LiDARä¼ æ„Ÿå™¨æ¨¡æ‹Ÿã€‚é€šè¿‡PGSRçš„å¹³é¢åŒ–é«˜æ–¯çº¦æŸè§£å†³LiDAR-RTä¸­é«˜æ–¯åŸºå…ƒ"é£˜åœ¨ç©ºä¸­"çš„é—®é¢˜ï¼Œæ˜¾è‘—æå‡å‡ ä½•ç²¾åº¦å’Œç‰©ç†çœŸå®æ€§ã€‚

## âœ¨ æ ¸å¿ƒç‰¹æ€§

- ğŸ”¬ **å¹³é¢åŒ–é«˜æ–¯çº¦æŸ**: åŸºäºPGSRçš„å‡ ä½•æ­£åˆ™åŒ–ï¼Œç¡®ä¿é«˜æ–¯åŸºå…ƒè´´åˆçœŸå®è¡¨é¢
- ğŸŒŠ **LiDARç‰©ç†å»ºæ¨¡**: ä½¿ç”¨çƒè°å‡½æ•°å»ºæ¨¡intensityå’Œray-dropçš„æ–¹å‘ç›¸å…³æ€§  
- ğŸ“Š **å¤šé€šé“æ¸²æŸ“**: åŒæ—¶è¾“å‡ºæ·±åº¦ã€å¼ºåº¦ã€ray-dropç­‰å¤šç»´LiDARä¿¡æ¯
- âš™ï¸ **é…ç½®åŒ–ç®¡ç†**: å±‚æ¬¡åŒ–YAMLé…ç½®ç³»ç»Ÿï¼Œæ”¯æŒå¤æ‚å®éªŒç®¡ç†
- ğŸš€ **é«˜æ•ˆè®­ç»ƒ**: ä¼˜åŒ–çš„è®­ç»ƒç®¡çº¿ï¼Œæ”¯æŒå¤§è§„æ¨¡åœºæ™¯é‡å»º

## ğŸ—ï¸ é¡¹ç›®æ¶æ„

```
PGSR/
â”œâ”€â”€ configs/                    # é…ç½®æ–‡ä»¶ç³»ç»Ÿ
â”‚   â”œâ”€â”€ base.yaml              # åŸºç¡€é…ç½®
â”‚   â”œâ”€â”€ kitti360/              # KITTI-360æ•°æ®é›†é…ç½®
â”‚   â”‚   â”œâ”€â”€ kitti360_base.yaml # æ•°æ®é›†åŸºç¡€é…ç½®
â”‚   â”‚   â””â”€â”€ static/            # é™æ€åœºæ™¯é…ç½®
â”‚   â”‚       â””â”€â”€ seq00.yaml     # åºåˆ—00é…ç½®
â”‚   â””â”€â”€ quick_test.yaml        # å¿«é€Ÿæµ‹è¯•é…ç½®
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ config_utils.py        # é…ç½®è§£æå·¥å…·
â”‚   â””â”€â”€ lidar_loss_utils.py    # LiDARæŸå¤±å‡½æ•°
â”œâ”€â”€ gaussian_renderer/
â”‚   â””â”€â”€ lidar_renderer.py      # LiDARæ¸²æŸ“å™¨
â”œâ”€â”€ scene/
â”‚   â”œâ”€â”€ gaussian_model.py      # æ‰©å±•çš„é«˜æ–¯æ¨¡å‹(æ”¯æŒLiDAR)
â”‚   â””â”€â”€ kitti360_dataset.py    # KITTI-360æ•°æ®åŠ è½½å™¨
â”œâ”€â”€ train_lidar_config.py      # é…ç½®åŒ–è®­ç»ƒè„šæœ¬
â””â”€â”€ agent/                     # é¡¹ç›®æ–‡æ¡£
    â”œâ”€â”€ guide.md               # é¡¹ç›®æŒ‡å—
    â”œâ”€â”€ tasks.md               # ä»»åŠ¡æ¸…å•
    â”œâ”€â”€ log.md                 # å·¥ä½œæ—¥å¿—
    â”œâ”€â”€ pgsr_simplified.md     # PGSRæŠ€æœ¯è¦ç‚¹
    â””â”€â”€ lidar_rt_simplified.md # LiDAR-RTæŠ€æœ¯è¦ç‚¹
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

```bash
# åˆ›å»ºcondaç¯å¢ƒ
conda create -n pgsr python=3.8
conda activate pgsr

# å®‰è£…ä¾èµ–
pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 -f https://download.pytorch.org/whl/torch_stable.html
pip install -r requirements.txt

# ç¼–è¯‘CUDAæ‰©å±•
cd submodules/diff-gaussian-rasterization
pip install -e .
cd ../simple-knn
pip install -e .
```

### é…ç½®åŒ–è®­ç»ƒ

```bash
# å¿«é€Ÿæµ‹è¯• (1000è½®è®­ç»ƒ)
python train_lidar_config.py -c configs/quick_test.yaml

# KITTI-360å®Œæ•´è®­ç»ƒ
python train_lidar_config.py -c configs/kitti360/static/seq00.yaml

# è‡ªå®šä¹‰å®éªŒåç§°
python train_lidar_config.py -c configs/quick_test.yaml --exp_name my_experiment

# å‘½ä»¤è¡Œå‚æ•°è¦†ç›–
python train_lidar_config.py -c configs/base.yaml --exp_name test_5k opt.iterations 5000
```

## ğŸ“ é…ç½®æ–‡ä»¶ç³»ç»Ÿ

### å±‚æ¬¡åŒ–é…ç½®è®¾è®¡

æœ¬é¡¹ç›®é‡‡ç”¨å±‚æ¬¡åŒ–çš„YAMLé…ç½®ç³»ç»Ÿï¼Œæ”¯æŒé…ç½®ç»§æ‰¿å’Œå‚æ•°è¦†ç›–ï¼š

```yaml
# configs/quick_test.yaml
parent_config: "kitti360/kitti360_base.yaml"  # ç»§æ‰¿KITTI-360é…ç½®

scene_id: "quick_test"
exp_name: "quick_debug"

opt:
  iterations: 1000                # è¦†ç›–çˆ¶é…ç½®çš„è®­ç»ƒè½®æ•°
  densification_interval: 50      # æ›´é¢‘ç¹çš„å¯†åŒ–
```

### é…ç½®æ–‡ä»¶è¯´æ˜

- **`base.yaml`**: åŒ…å«æ‰€æœ‰PGSRå’ŒLiDARå‚æ•°çš„åŸºç¡€é…ç½®
- **`kitti360/kitti360_base.yaml`**: KITTI-360æ•°æ®é›†ç‰¹åŒ–å‚æ•°
- **`kitti360/static/seq00.yaml`**: åºåˆ—00çš„å…·ä½“åœºæ™¯é…ç½®
- **`quick_test.yaml`**: å¼€å‘è°ƒè¯•ç”¨çš„å¿«é€Ÿæµ‹è¯•é…ç½®

### æ ¸å¿ƒå‚æ•°è¯´æ˜

```yaml
# æ¨¡å‹å‚æ•°
model:
  sh_degree: 3                   # çƒè°å‡½æ•°é˜¶æ•°
  enable_lidar: true             # å¯ç”¨LiDARæ¨¡å¼
  planar_constraint: true        # PGSRå¹³é¢çº¦æŸ
  geometric_regularization: true # å‡ ä½•æ­£åˆ™åŒ–

# LiDARæŸå¤±æƒé‡
opt:
  lambda_depth_l1: 0.1          # æ·±åº¦L1æŸå¤±
  lambda_intensity_l1: 0.85     # å¼ºåº¦L1æŸå¤±  
  lambda_raydrop_bce: 0.01      # Ray-drop BCEæŸå¤±
  lambda_planar: 100.0          # PGSRå¹³é¢åŒ–æŸå¤±
```

## ğŸ“Š æŠ€æœ¯ç‰¹ç‚¹

### PGSRå‡ ä½•çº¦æŸ

- **å¹³é¢åŒ–æŸå¤±**: çº¦æŸé«˜æ–¯åŸºå…ƒçš„æœ€å°scaleæ¥è¿‘0ï¼Œå½¢æˆå¹³é¢ç»“æ„
- **æ— åæ·±åº¦æ¸²æŸ“**: åŸºäºå¹³é¢å‚æ•°è®¡ç®—ç²¾ç¡®æ·±åº¦ï¼Œé¿å…curved surfaceé—®é¢˜
- **å¤šè§†å›¾å‡ ä½•çº¦æŸ**: ç¡®ä¿å¤šè§†è§’å‡ ä½•ä¸€è‡´æ€§

### LiDARç‰©ç†å»ºæ¨¡

- **çƒè°å‡½æ•°å»ºæ¨¡**: ä½¿ç”¨çƒè°å‡½æ•°è¡¨ç¤ºintensityå’Œray-dropçš„æ–¹å‘ç›¸å…³æ€§
- **æ¦‚ç‡é®æŒ¡æ¨¡å‹**: åŸºäºSigmoidå‡½æ•°çš„ray-dropæ¦‚ç‡å»ºæ¨¡
- **360åº¦æ”¯æŒ**: å®Œæ•´æ”¯æŒ360åº¦LiDARè§†åœºè§’

## ğŸš€ é¡¹ç›®çŠ¶æ€

**å½“å‰è¿›åº¦: 85% å®Œæˆ**

### âœ… å·²å®Œæˆé˜¶æ®µ
- **é˜¶æ®µ1**: é¡¹ç›®è®¾ç½®å’Œç¯å¢ƒå‡†å¤‡ (100%å®Œæˆ)
- **é˜¶æ®µ2**: æ ¸å¿ƒåŠŸèƒ½è¿ç§» (100%å®Œæˆ)  
- **é…ç½®æ–‡ä»¶ç³»ç»Ÿ**: å®éªŒç®¡ç†æ ‡å‡†åŒ– (100%å®Œæˆ)
- **é˜¶æ®µ3**: PGSRå‡ ä½•çº¦æŸé›†æˆ (100%å®Œæˆ) ğŸ†•

### ğŸš§ å½“å‰é˜¶æ®µ
- **é˜¶æ®µ4**: ç³»ç»Ÿä¼˜åŒ–å’Œæµ‹è¯• (è¿›è¡Œä¸­)
  - æ— åæ·±åº¦æ¸²æŸ“ä¼˜åŒ–
  - æŸå¤±å‡½æ•°æƒé‡å¹³è¡¡è°ƒä¼˜
  - KITTI-360å®Œæ•´è®­ç»ƒæµ‹è¯•
  - æ€§èƒ½åŸºå‡†æµ‹è¯•å’Œå¯¹æ¯”

### ğŸ†• é˜¶æ®µ3æ–°å¢åŠŸèƒ½

#### PGSRå‡ ä½•çº¦æŸé›†æˆ
- **å¹³é¢åŒ–çº¦æŸ**: é€šè¿‡`compute_planar_loss()`çº¦æŸé«˜æ–¯åŸºå…ƒä¸ºå¹³é¢çŠ¶
- **å•è§†å›¾å‡ ä½•æ­£åˆ™åŒ–**: ç¡®ä¿æ¸²æŸ“æ³•å‘é‡ä¸æ·±åº¦æ³•å‘é‡ä¸€è‡´æ€§
- **è¾¹ç¼˜æ„ŸçŸ¥çº¦æŸ**: åœ¨å›¾åƒè¾¹ç¼˜åŒºåŸŸå‡å°‘å‡ ä½•çº¦æŸå¼ºåº¦
- **å®Œæ•´PGSRæŸå¤±å·¥å…·**: `utils/pgsr_loss_utils.py`æä¾›å®Œæ•´å‡ ä½•çº¦æŸåŠŸèƒ½
- **é…ç½®åŒ–ç®¡ç†**: æ‰€æœ‰PGSRå‚æ•°é€šè¿‡YAMLé…ç½®æ–‡ä»¶ç®¡ç†

#### æ ¸å¿ƒæ”¹è¿›
- è§£å†³äº†LiDAR-RTä¸­é«˜æ–¯åŸºå…ƒ"é£˜åœ¨ç©ºä¸­"çš„é—®é¢˜
- æ˜¾è‘—æå‡äº†å‡ ä½•æ¸²æŸ“ç²¾åº¦å’ŒçœŸå®æ€§
- å®ç°äº†å®Œæ•´çš„PGSR+LiDARè”åˆè®­ç»ƒç®¡çº¿

## ğŸ“ˆ é¡¹ç›®è¿›åº¦

- âœ… **é˜¶æ®µ1**: ç¯å¢ƒæ­å»ºå’Œä»£ç åˆ†æ (å·²å®Œæˆ)
- âœ… **é˜¶æ®µ2**: LiDAR-RTæ ¸å¿ƒåŠŸèƒ½è¿ç§» (å·²å®Œæˆ) 
- âœ… **é…ç½®ç³»ç»Ÿ**: å®éªŒç®¡ç†æ ‡å‡†åŒ– (å·²å®Œæˆ)
- ğŸš§ **é˜¶æ®µ3**: PGSRå‡ ä½•çº¦æŸé›†æˆ (è¿›è¡Œä¸­)
- â³ **é˜¶æ®µ4**: ç³»ç»Ÿé›†æˆå’Œæµ‹è¯•
- â³ **é˜¶æ®µ5**: æ–‡æ¡£å’Œå‘å¸ƒ

è¯¦ç»†è¿›åº¦è¯·æŸ¥çœ‹ [ä»»åŠ¡æ¸…å•](agent/tasks.md) å’Œ [å·¥ä½œæ—¥å¿—](agent/log.md)ã€‚

## ğŸ”§ å¼€å‘æŒ‡å—

### æ·»åŠ æ–°çš„é…ç½®

1. åœ¨`configs/`ç›®å½•ä¸‹åˆ›å»ºæ–°çš„YAMLæ–‡ä»¶
2. ä½¿ç”¨`parent_config`æŒ‡å®šç»§æ‰¿çš„çˆ¶é…ç½®
3. åªè¦†ç›–éœ€è¦ä¿®æ”¹çš„å‚æ•°

### æ‰©å±•LiDARå±æ€§

1. åœ¨`GaussianModel`ä¸­æ·»åŠ æ–°çš„çƒè°ç³»æ•°å±æ€§
2. åœ¨`lidar_renderer.py`ä¸­å®ç°å¯¹åº”çš„æ¸²æŸ“é€»è¾‘
3. åœ¨æŸå¤±å‡½æ•°ä¸­æ·»åŠ å¯¹åº”çš„ç›‘ç£ä¿¡å·

### è°ƒè¯•å’Œæµ‹è¯•

```bash
# ä½¿ç”¨å¿«é€Ÿé…ç½®è¿›è¡Œå¼€å‘æµ‹è¯•
python train_lidar_config.py -c configs/quick_test.yaml --exp_name debug_test

# å¯ç”¨å¼‚å¸¸æ£€æµ‹
python train_lidar_config.py -c configs/quick_test.yaml --detect_anomaly
```

## ğŸ“– ç›¸å…³è®ºæ–‡

- **PGSR**: Planar Gaussian Splatting for High-Quality Surface Reconstruction
- **LiDAR-RT**: Real-time LiDAR Point Cloud Simulation using Gaussian Splatting

## ğŸ¤ è´¡çŒ®æŒ‡å—

1. Fork é¡¹ç›®
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. å¼€å¯ Pull Request

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®åŸºäº MIT è®¸å¯è¯å¼€æº - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…ã€‚

## ğŸ™ è‡´è°¢

æ„Ÿè°¢PGSRå’ŒLiDAR-RTé¡¹ç›®çš„å¼€æºè´¡çŒ®ï¼Œä¸ºæœ¬é¡¹ç›®æä¾›äº†é‡è¦çš„æŠ€æœ¯åŸºç¡€ã€‚
